# Theory this is a x86_64 image
FROM ubuntu:latest AS base

USER root
ARG python_version="3.8"

ENV workdir="/my_workdir"

RUN apt-get update &&  apt-get install -y software-properties-common && apt-get install -y openjdk-11-jdk && \
    apt-get install -y wget

# Add deadsnakes PPA (for getting latest python version)
RUN add-apt-repository ppa:deadsnakes/ppa -y && apt-get update

RUN apt-get install -y python3 python3-pip python3-venv

# Set default Python version
RUN ln -sf /usr/bin/python3 /usr/bin/python

# This line is no longer necessary. Pyspark lib is already included in requirements.txt
#RUN pip install --break-system-packages pyspark

# Download and extract Spark binaries
RUN python3 -m pip config set global.break-system-packages true

RUN wget -qO- https://archive.apache.org/dist/spark/spark-3.5.5/spark-3.5.5-bin-hadoop3.tgz | tar xvz -C /opt/ &&
mv spark-3.5.5-bin-hadoop3 /opt/spark

# Set environment variables
ENV SPARK_HOME=/opt/spark-3.5.5-bin-hadoop3
ENV PATH=$SPARK_HOME/bin:$PATH
ENV PYSPARK_PYTHON=python3

COPY requirements.txt .

RUN pip install -r requirements.txt

# Set JAVA_HOME environment variable
ENV JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
ENV PATH="${JAVA_HOME}/bin:${PATH}"

# Verify Java installation
RUN java -version

CMD ["/bin/bash"]

USER 185